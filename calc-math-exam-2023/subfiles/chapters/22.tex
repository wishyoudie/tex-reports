\documentclass[../../calc-math-exam-2023.tex]{subfiles}
\begin{document}
    \section{Методы бисекции, секущих, обратной параболической интерполяции для решения нелинейных уравнений. Подпрограмма \textbf{ZEROIN}.}\label{sec:ch22}
    Большинство методов, предназначенных для нахождения корней нелинейного уравнения $f(x) = 0$ предполагает, что
    заранее определены некоторые промежутки, где это уравнение имеет только один корень. Поэтому задаче нахождения
    решения с заданной точностью предшествует этап \emph{отделения корней}, связанный с исследованием количества,
    характера расположения корней и нахождением их грубого приближения. Уравнение может вообще не иметь решений, а может
    встретиться ситуация, когда корней бесконечно много. Этот этап формализуется лишь частично и чаще относится к области
    математического искусства. Универсального эффективного метода в общем случае нет. На практике в большинстве случаев
    ограничиваются приближенным построением графика $y = f(x)$ или составлением таблицы для $f(x)$ с некоторым шагом и
    нахождением участков, где функция меняет знак. При этом шаг не должен быть слишком крупным (должна быть уверенность
    в не более, чем одном нуле между узлами), а, с другой стороны, он не должен быть излишне мал (иначе резко возрастает
    объем вычислений). Иногда удобно преобразовать уравнение к виду $\displaystyle \varphi(x) = \mu(x)$, а затем искать
    точку пересечения графиков $y = \varphi(x)$ и $y = \mu(x)$, что и будет начальным приближением.

    В рамках раздела будем использовать следующие обозначения: $x^{*} = x_n + \varepsilon_n$, где $x^{*}$ -- точное
    решение, $x_n$ -- очередное приближение к решению, $\varepsilon_n$ -- погрешность.

    Остановимся лишь на вещественных корнях уравнения $f(x) = 0$, считая, что функция $f(x)$ нужное число раз
    непрерывно дифференцируема для выбранного метода и установлен промежуток $[a, b]$, где находится единственный корень.
    При этом $\displaystyle f(a) \cdot f(b) < 0$. Тогда наиболее простым и абсолютно надежным способом является
    \emph{метод биссекции} (или метод \emph{дихотомии}, \emph{половинного деления}). Его алгоритм представим следующим
    образом:
    \begin{enumerate}
        \item Вычислить $f(a)$ и $f(b)$.
        \item Положить $\displaystyle c = \frac{a + b}{2}$ и вычислить $f(c)$.
        \item Если $\text{sign}\left( f(a) \right) == \text{sign}\left( f(c) \right)$, заменить $a$ на $c$. Иначе заменить $b$ на $c$.
        \item Если $\displaystyle |b - a| > \varepsilon$, перейти к шагу 2. Иначе закончить вычисления.
    \end{enumerate}
    Одна итерация алгоритма позволяет \emph{гарантированно} сократить исходный промежуток в два раза независимо от вида
    функции.

    Другой алгоритм, называемый \emph{методом секущих}, можно построить, используя интерполяционный полином Лагранжа
    первой степени для $f(x)$ по двум узлам $a$ и $b$. Тогда нуль этого полинома принимается в качестве очередного
    приближения к корню уравнения.
    \begin{equation*}
        Q_1(x) = \frac{x - b}{a - b}f(a) + \frac{x - a}{b - a}f(b), \qquad c = a - \frac{b - a}{f(b) - f(a)}f(a)
    \end{equation*}
    Новый промежуток будет $[c, b]$ или $[a, c]$ в зависимости от знака $f(x)$ в точке $c$. Скорость сходимости метода
    секущих определяется неравенством $\displaystyle \left| x^* - x_{k+1} \right| \leq \left| x^* - x_k \right|^{1,618}$.
    Следует отметить, что замедление сходимости этого алгоритма часто наблюдается, когда очередное приближение
    получается слишком близко к одному из концов промежутка.

    Если функция вычислена более, чем в двух точках, то эта информация может быть использована в дальнейшем. Так, в
    \emph{методе обратной квадратичной интерполяции} строится интерполяционный полином второй степени по точкам
    $x_k, x_{k-1}, x_{k-2}$. Для обратной функции с выполнением условий $\displaystyle x_i = g(f_i), i = k, k-1, k-2$.
    В качестве следующего приближения берется $\displaystyle x_{k+1} = g(0)$. Одна из предыдущих точек удаляется.
    Важно, чтобы три значения $f_i$ были различными, тогда исключается деление на нуль, и сходимость метода определяется
    неравенством $\displaystyle \left| x^* - x_{k+1} \right| \leq \left| x^* - x_k \right|^{1,839}$.
    \vspace{10pt}

    Сочетание методов бисекции и обратной квадратичной интерполяции реализовно в процедуре-функции \verb|ZEROIN(A, B, F, EPS)|.

    \bf{A}, \bf{B} -- концы интервала.

    \bf{F} -- имя процедуры-функции, имеющей лишь один аргумент, для которого вычисляется $f(x)$.

    \bf{EPS} -- граница погрешности, допустимой в результате.
    \vspace{10pt}

    Основным алгоритмом является метод обратной квадратической интерполяции (если узлы не являются различными, то
    используется метод секущих). Если очередное приближение получается слишком близким к одному из краев промежутка, то
    осуществляется переключение на метод биссекции.
\end{document}