\section{Аппроксимация функций. Задача интерполирования.}\label{sec:ch05}

\subsection{Аппроксимация функций.}
В данной теме аппроксимация означает \emph{замену одной функциональной зависимости другой}. Поскольку на практике часто
возникает потребность дифференцировать, интегрировать или использовать эту функцию в различных расчетах, целесообразно
выбирать аппроксимирующую функцию, исходя из простоты ее вида. Возможность выбора обосновывается следующей теоремой.
\begin{theorem}[Теорема Вейерштрасса]
    Пусть $f(x)$ непрерывна на $[a, b]$. Тогда
    \begin{equation*}
        \forall \varepsilon > 0 \quad \exists P_n(x) \quad n = n(\varepsilon) : \quad \max |f(x) - P_n(x)| < \varepsilon
    \end{equation*}
\end{theorem}
Однако, эта теорема лишь гарантирует существование, но не дает гарантии, что такой полином можно построить при помощи
практического алгоритма.

Для того чтобы можно было сравнивать различные варианты аппроксимации, следует ввести критерий близости. Например,
максимум модуля отклонения исходной функции $f(x)$ от аппроксимирующей $g(x)$ на заданном промежутке:
\begin{equation}
    \delta = \max_{x \in [a, b]} |f(x) - g(x)|\label{eq:criteria1}
\end{equation}
или так называемый <<среднеквадратичный критерий>>
\begin{equation}
    \rho^2 = \int_a^b \left( f(x) - g(x) \right)^2 dx\label{eq:criteria2}
\end{equation}
В случае если $f(x)$ определена таблично заданным набором точек, может быть использован аналог
критерия~\eqref{eq:criteria2}
\begin{equation}
    \rho^2 = \sum_{k=1}^m \left( f(x_k) - g(x_k) \right)^2\label{eq:criteria3}
\end{equation}
Лучшей оказывается аппроксимирующая функция, обладающая наименьшей величиной $\delta$ или $\rho^2$. \emph{Заметим, что} только
решаемая задача диктует выбираемый критерий близости, который, в свою очередь, позволяет выбрать лучшую аппроксимацию.

\subsection{Постановка задачи интерполирования}
Будем приближать исходную функцию, заданную таблично $\displaystyle X = \left\{x_0, x_1,\dots,x_m\right\},\,F = \left\{f(x)\,|\, x \in X\right\}$
обобщенным многочленом
\begin{equation}
    Q_m(x) = a_0 \varphi_0(x) + a_1 \varphi_1(x) + \dots + a_m \varphi_m(x) = \sum_{k=0}^m a_k\varphi_k(x)\label{eq:inter_polynom_defintion}
\end{equation}
где $\left\{ \varphi_k \right\}$ -- заданный набор линейно независимых функций, а коэффициенты $a_i$ подлежат определению. В
качестве критерия близости выбирается совпадение значений $f(x)$ и $Q_m(x)$ в узлах таблицы
\begin{equation}
    Q_m(x_i) = f(x_i), \qquad i = 0,1,\dots,m\label{eq:inter_polynom_definition2}
\end{equation}
\begin{definition}[Интерполяционный многочлен]
    Полином~\eqref{eq:inter_polynom_defintion} называется \emph{интерполяционным многочленом}, а $x_k$ -- \emph{узлами
    интерполирования}.
\end{definition}

Равенства~\eqref{eq:inter_polynom_definition2} представляют собой СЛАУ относительно искомых коэффициентов обобщенного
многочлена $a_0, a_1, \dots, a_m$. Эта система имеет единственное решение, если ее определитель отличен от нуля:
\begin{equation*}
    \det
    \begin{pmatrix}
        \varphi_0(x_0) & \varphi_1(x_0) & \dots & \varphi_m(x_0) \\
        \varphi_0(x_1) & \varphi_1(x_1) & \dots & \varphi_m(x_1) \\
        \dots          & \dots          & \dots & \dots          \\
        \varphi_0(x_m) & \varphi_1(x_m) & \dots & \varphi_m(x_m) \\
    \end{pmatrix}
    \neq 0
\end{equation*}

Наиболее популярной является полиномиальная аппроксимация:
\begin{equation*}
    \varphi_k(x) = x^k \qquad Q_m(x) = a_0 + a_1 x + a_2 x^2 + \dots + a_m x^m
\end{equation*}

\begin{definition}[Определитель Вандермонда]
    Определитель СЛАУ для случая полиномиальной аппроксимации называется определителем Вандермонда и имеет следующий вид:
    \begin{equation*}
        \begin{vmatrix}
            1     & x_0   & \dots & x_0^n \\
            1     & x_1   & \dots & x_1^n \\
            \dots & \dots & \dots & \dots \\
            1     & x_n   & \dots & x_n^n
        \end{vmatrix}
    \end{equation*}
\end{definition}
Определитель Вандермонда отличен от нуля, и задача имеет единственное решение, если узлы интерполирования
$x_0, x_1, \dots, x_m$ различны.
