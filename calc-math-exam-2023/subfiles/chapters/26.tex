\section{Методы Рунге-Кутты. Подпрограмма \textbf{RKF45}.}\label{sec:ch26}
Метод трапеций является неявным. Что произойдет, если вычислить $\bf{x}_{n+1}$ сначала по формуле~\eqref{eq:diff_left_triangles},
а затем уточнить по формуле~\eqref{eq:diff_traps}?
\begin{equation}
    \bf{x}_{n+1}^* = \bf{x}_n + h\bf{f}(t_n, \bf{x}_n),
\end{equation}
\begin{equation*}
    \bf{x}_{n+1} = \bf{x}_n + \frac{h}{2}\left( \bf{f}(t_n, \bf{x}_n) + \bf{f}(t_{n+1}, \bf{x}_{n+1}) \right)
\end{equation*}

Полученный одношаговый метод, называемый \emph{методом Эйлера-Коши}, является уже явным. Как будет показано, он имеет
вторую степень, которая достигается ценой двух вычислений функции $\bf{f}(t, \bf{x})$ на каждом шаге.

Приведем еще один пример. Сделаем полшага с помощью явного метода ломаных Эйлера, а затем используем полученное значение
в квадратурной формуле средних прямоугольников, примененной к интегралу~\eqref{eq:koshi_2}.
\begin{equation}
    \bf{x}_{n+1/2}^* = \bf{x}_n + \frac{h}{2}\bf{f}(t_n, \bf{x}_n)
\end{equation}
\begin{equation*}
    \bf{x}_{n+1} = \bf{x}_n + h\bf{f}\left( t_n + \frac{h}{2}, \bf{x}_{n+1/2}^* \right)
\end{equation*}
Этот метод, называемый \emph{усовершенствованным методом ломаных Эйлера}, также имеет вторую степень и требует
двукратного вычисления $\bf{f}(t, \bf{x})$. Приведенные примеры укладываются в следующую схему. Вычислим
$\bf{f}(t, \bf{x})$ дважды в некоторых точках и их линейную комбинацию используем для получения $\bf{x}_{n+1}$
\begin{equation}
    \bf{k}_1 = h\bf{f}(t_n, \bf{x}_n) \label{eq:rk1}
\end{equation}
\begin{gather*}
    \bf{k}_2 = h\bf{f}\left( t_n + \alpha_2 h, \bf{x}_n + \beta_{21} \bf{k}_1 \right) \\
    \bf{x}_{n+1} = \bf{x}_n + p_1 \bf{k}_1 + p_2 \bf{k}_2
\end{gather*}
Параметры $p_1, p_2, \alpha_2, \beta_{21}$ будем выбирать так, чтобы разложение формулы метода~\eqref{eq:rk1} в ряд максимальным
образом совпадало с разложением точного решения~\eqref{eq:dcmf_precise}. С этой целью отметим, что согласно~\eqref{eq:koshi_1}
\begin{equation*}
    \bf{x}' = \bf{f}(t, \bf{x}) \qquad \bf{x}'' = \frac{\partial \bf{f}}{\partial t} + \frac{\partial \bf{f}}{\partial \bf{x}}\bf{f}
\end{equation*}
и~\eqref{eq:dcmf_precise} имеет вид
\begin{equation*}
    \bf{x}_{n+1} = \bf{x}_n + h\bf{f}(t_n, \bf{x}_n) + \frac{h^2}{2}\left( \frac{\partial \bf{f}}{\partial t} + \frac{\partial \bf{f}}{\partial \bf{x}} \right) + \ldots
\end{equation*}
Раскладывая~\eqref{eq:rk1} в ряд и приравнивая коэффициенты при соответствующих степенях $h$, добиваемся того, что
формула~\eqref{eq:rk1} задает методы второй степени
\begin{equation*}
    \bf{x}_{n+1} = \bf{x}_n + p_1 h \bf{f}_n + p_2 h\left( \bf{f}_n + \alpha_2 h \frac{\partial \bf{f}}{\partial t} + \beta_{21} h \frac{\partial \bf{f}}{\partial \bf{x}}\bf{f} + \ldots \right)
\end{equation*}
\begin{equation}
    p_1 + p_2 = 1, \quad p_2 \alpha_2 = 1/2, \quad p_2 \beta_{21} = 1/2 \label{eq:rk2}
\end{equation}
Условия~\eqref{eq:rk2} представляют собой три уравнения с четырьмя неизвестными и, следовательно, методов второй степени
вида~\eqref{eq:rk1} бесконечно много. В частности, определяя параметры $p_1 = p_2 = 1/2, \, \alpha_2 = \beta_{21} = 1$, получаем
метод Эйлера-Коши, а набор $p_1 = 0, \, p_2 = 1, \alpha_2 = \beta_{21} = 1/2$ задает усовершенствованный метод ломаных Эйлера. В
то же время построить метод третьей степени с двумя вычислениями $\bf{f}(t, \bf{x})$ не удается.

Увеличивая число вычислений функции $\bf{f}(t, \bf{x})$ на одном шаге, получаем семейство методов Рунге-Кутты в виде
\begin{gather*}
    \bf{k}_1 = h\bf{f}(t_n, \bf{x}_n), \, \bf{k}_r = h\bf{f}\left( t_n + \alpha_r h, \bf{x}_n + \sum_{i=1}^{r-1} \beta_{ri}\bf{k}_i \right), \quad r=1,2,\ldots,s\\
    \bf{x}_{n+1} = \bf{x}_n + \sum_{r=1}^{s} p_r \bf{k}_r
\end{gather*}

Коэффициенты методов вычисляем аналогично тому, как это было выполнено для методов второй степени. При этом, если для
метода второй степени достаточно рассчитать $\bf{f}(t, \bf{x})$ два раза на одном шаге, то метод третьей степени требует
трех вычислений $\bf{f}(t, \bf{x})$, а метод четвертой степени -- четырех таких вычислений. Все эти методы, как и методы
второй степени, образуют семейства. Среди них наиболее популярными являются следующие методы третьей степени:
\begin{equation*}
    \bf{k}_1 = h\bf{f}(t_n, \bf{x}_n), \qquad \bf{k}_2 = h\bf{f}\left( t_n + \frac{h}{2}, \bf{x}_n + \frac{\bf{k}_1}{2} \right)
\end{equation*}
\begin{equation}
    \bf{k}_3 = h\bf{f}\left( t_n + h, \bf{x}_n - \bf{k}_1 + 2\bf{k}_2 \right), \qquad \bf{x}_{n+1} = \bf{x}_n + \left( \frac{\bf{k}_1 + 4\bf{k}_2 + \bf{k}_3}{6} \right)
\end{equation}
и четвертой степени:
\begin{gather*}
    \bf{k}_1 = h\bf{f}(t_n, \bf{x}_n), \qquad \bf{k}_2 = h\bf{f}\left( t_n + \frac{h}{2}, \bf{x}_n + \frac{\bf{k}_1}{2}\right) \\
    \bf{k}_3 = h\bf{f}\left( t_n + \frac{h}{2}, \bf{x}_n + \frac{\bf{k}_2}{2} \right), \qquad \bf{k}_4 = h\bf{f}\left( t_n + h, \bf{x}_n + \bf{k}_3 \right)
\end{gather*}
\begin{equation}
    \bf{x}_{n+1} = \bf{x}_n + \left( \frac{\bf{k}_1 + 2\bf{k}_2 + 2\bf{k}_3 + \bf{k}_4}{6} \right)
\end{equation}

Как уже отмечалось, если функция $\bf{f}(t, \bf{x})$ не зависит от \bf{x}, то все методы интегрирования дифференциальных
уравнений превращаются в соответствующие им квадратурные формулы.

С увеличением степени метода резко возрастает число параметров $p_r, \, \alpha_r, \, \beta_{ri}$, а также число нелинейных
уравнений для их определения. Оказывается, что метод Рунге-Кутты четвертой степени является последним методом, у которого
количество вычислений $\bf{f}(t, \bf{x})$ на одном шаге совпадает со степенью метода. Уже метод Рунге-Кутты пятой степени
требует вычислять функцию $\bf{f}(t, \bf{x})$ шесть раз, шестой степени -- 7 раз, седьмой степени -- 9, восьмой -- 11. С
дальнейшим ростом степени методов трудности их построения растут по экспоненте.

Теперь обратимся к такому важному моменту, как контроль погрешности метода в процессе интегрирования. Представляется
весьма желательным использование переменного шага интегрирования подобно тому, как это делается в программах, реализующих
адаптивные квадратурные формулы (например, программа \verb|QUANC8|). Хотелось бы выбирать маленький шаг там, где решение
меняется быстро, и большой, где оно меняется относительно медленно. Оценивать погрешность по отбрасываемому члену
разложения чрезвычайно неудобно. Поэтому на практике используются различные другие подходы для контроля локальной
погрешности методов. Один их них состоит в сравнении на каждом шаге интегрирования решений, получаемых по формулам
методов различных степеней. Этот подход реализован в программе \verb|RKF45|, построенной на методах Рунге-Кутты-Фельберга
четвертой и пятой степени. Фельбергу удалось так подобрать параметры методов, что одни и те же шесть вычислений
$\bf{k}_r$ функции $\bf{f}(t, \bf{x})$ с различными весами $p_r$ используются для получения решения методами и четвертой,
и пятой степени
\begin{equation*}
    \bf{x}_{n+1}^{(4)} = \bf{x}_n + \sum_{r=1}^{6} p_r \bf{k}_r, \quad \bf{x}_{n+1}^{(5)} = \bf{x}_n + \sum_{r=1}^{6} p_r^* \bf{k}_r,
    \quad \bf{x}_{n+1}^{(5)} - \bf{x}_{n+1}^{(4)} = \sum_{r=1}^{6} \left( p_r^* - p_r \right)\bf{k}_r
\end{equation*}
Тогда разность между этими решениями может использоваться для контроля величины шага дискретности.

\subsection{Подпрограмма \textbf{RKF45}.}
\begin{verbatim}
        RKF45(F, N, X, T, TOUT, RE, AE, IFLAG, WORK, IWORK)
\end{verbatim}
\bf{F} -- имя процедуры, написанной пользователем для вычисления правых частей системы~\eqref{eq:koshi_1}. Эта программа,
в свою очередь, должна иметь следующие параметры: \verb|F(T, X, DX)| (\bf{X} -- вектор решения в точке \bf{T}, а \bf{DX} -- вектор производных)

\bf{N} -- количество интегрируемых уравнений;

\bf{X} -- вектор решения размерностью \bf{N} в точке \bf{T} на входе в программу и в точке \bf{TOUT} при выходе из нее;

\bf{T} -- начальное значение независимой переменной на входе в программу (при нормальном выходе это \bf{TOUT});

\bf{TOUT} -- точка выхода по независимой переменной;

\bf{RE, AE} -- границы относительной и абсолютной погрешностей;

\bf{WORK} -- рабочий вещественный массив размерности $6\bf{N} + 3$;

\bf{IWORK} -- рабочий целый массив размерности не менее 5;

\bf{IFLAG} -- указатель режима интегрирования. Обычно при первом обращении на входе $\bf{IFLAG} = 1$, а при последующих
обращениях на входе $\bf{IFLAG} = 2$. Нормальное выходное значение $\bf{IFLAG} = 2$. Другие выходные значения указывают
на возникшие отклонения от нормального процесса:
\begin{enumerate}
    \item[$=3$ --] заданное значение \bf{RE} оказалось слишком малым и требуется его увеличить;
    \item[$=4$ --] потребовалось более 3000 вычислений $\bf{f}(t, \bf{x})$ (это отвечает приблизительно 500 шагам).
    Можно, не изменяя \bf{IFLAG}, снова обратиться к программе или, если система является жесткой, применить специальные
    алгоритмы решения жестких систем.
    \item[$=5$ --] решение обратилось в нуль, а \bf{AE} равно нулю. Требуется задать ненулевое значение \bf{AE}.
    \item[$=6$ --] требуемая точность не достигнута даже при наименьшей допустимой величине шага и требуется увеличить
    \bf{AE} и \bf{RE}.
    \item[$=7$ --] слишком большое число требуемых выходных точек препятствует выбору естественной величины шага (он
    может быть значительно увеличен при заданной точности). Нужно или увеличить \bf{TOUT-T} или задать значение
    $\bf{IFLAG} = 2$ и продолжить работу программы.
    \item[$=8$ --] неправильное задание параметров процедуры (например, $\bf{N} < 0$)
\end{enumerate}
